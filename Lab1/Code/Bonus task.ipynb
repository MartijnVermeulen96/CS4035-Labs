{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some imports might be redundant because the code was split up into pieces\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot size\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_predict, y_true):\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    for i in range(len(y_predict)):\n",
    "        if y_true[i]==1 and y_predict[i]==1:\n",
    "            TP += 1\n",
    "        if y_true[i]==0 and y_predict[i]==1:\n",
    "            FP += 1\n",
    "        if y_true[i]==1 and y_predict[i]==0:\n",
    "            FN += 1\n",
    "        if y_true[i]==0 and y_predict[i]==0:\n",
    "            TN += 1\n",
    "    \n",
    "    return TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouping_features(x_train, x_test, column_names):\n",
    "    card_column = column_names.index(\"card_id\")\n",
    "    ip_column = column_names.index(\"ip_id\")\n",
    "    mail_column = column_names.index(\"mail_id\")\n",
    "\n",
    "    temp_df_train = pd.DataFrame(x_train)\n",
    "    temp_df_train = pd.concat([temp_df_train[card_column], pd.DataFrame(y_train)], axis=1)\n",
    "    temp_df_train.columns = ['card', 'fraud']\n",
    "    grouped_card = temp_df_train.groupby('card').sum()\n",
    "    resulting_df_card = grouped_card[grouped_card['fraud'] > 0]\n",
    "\n",
    "    temp_df_train = pd.DataFrame(x_train)\n",
    "    temp_df_train = pd.concat([temp_df_train[ip_column], pd.DataFrame(y_train)], axis=1)\n",
    "    temp_df_train.columns = ['ip', 'fraud']\n",
    "    grouped_ip = temp_df_train.groupby('ip').sum()\n",
    "    resulting_df_ip = grouped_ip[grouped_ip['fraud'] > 0]\n",
    "\n",
    "    temp_df_train = pd.DataFrame(x_train)\n",
    "    temp_df_train = pd.concat([temp_df_train[mail_column], pd.DataFrame(y_train)], axis=1)\n",
    "    temp_df_train.columns = ['mail', 'fraud']\n",
    "    grouped_mail = temp_df_train.groupby('mail').sum()\n",
    "    resulting_df_mail = grouped_mail[grouped_mail['fraud'] > 0]\n",
    "    \n",
    "    \n",
    "    mail_features_train = pd.DataFrame(x_train[:,mail_column])[0].apply(lambda x: get_value(resulting_df_mail, x, 'fraud'))\n",
    "    card_features_train = pd.DataFrame(x_train[:,card_column])[0].apply(lambda x: get_value(resulting_df_card, x, 'fraud'))\n",
    "    ip_features_train = pd.DataFrame(x_train[:,ip_column])[0].apply(lambda x: get_value(resulting_df_ip, x, 'fraud'))\n",
    "    \n",
    "    train_features = pd.concat([mail_features_train, card_features_train, ip_features_train], axis=1).values\n",
    "    \n",
    "    mail_features_test = pd.DataFrame(x_test[:,mail_column])[0].apply(lambda x: get_value(resulting_df_mail, x, 'fraud'))\n",
    "    card_features_test = pd.DataFrame(x_test[:,card_column])[0].apply(lambda x: get_value(resulting_df_card, x, 'fraud'))\n",
    "    ip_features_test = pd.DataFrame(x_test[:,ip_column])[0].apply(lambda x: get_value(resulting_df_ip, x, 'fraud'))\n",
    "    \n",
    "    test_features = pd.concat([mail_features_test, card_features_test, ip_features_test], axis=1).values\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Read the data in pandas\n",
    "data = pd.read_csv(\"data_for_student_case.csv\")\n",
    "data['bookingdate'] =  pd.to_datetime(data['bookingdate'])\n",
    "data['creationdate'] =  pd.to_datetime(data['creationdate'])\n",
    "\n",
    "# Delete the refused transactions (but keep them for later use maybe)\n",
    "\n",
    "refused_data = data.loc[data['simple_journal'] == \"Refused\", :]\n",
    "dataset = data.loc[data['simple_journal'] != \"Refused\", :].copy()\n",
    "dataset['bool_fraud'] = (dataset['simple_journal'] == \"Chargeback\").copy().astype(int)\n",
    "dataset['bool_valid'] = (dataset['simple_journal'] == \"Settled\").copy().astype(int)\n",
    "\n",
    "# Do some preprocessing for the ML algorithms\n",
    "finalset = dataset.copy()\n",
    "finalset['mail_id'] = finalset['mail_id'].str.replace('email','')\n",
    "finalset['ip_id'] = finalset['ip_id'].str.replace('ip','')\n",
    "finalset['card_id'] = finalset['card_id'].str.replace('card','')\n",
    "\n",
    "\n",
    "## Transform the data into onehot vectors\n",
    "targets_for_onehot = ['issuercountrycode', 'txvariantcode','currencycode', 'shoppercountrycode', 'shopperinteraction', 'cardverificationcodesupplied', 'cvcresponsecode']\n",
    "\n",
    "new_df = pd.DataFrame([])\n",
    "\n",
    "for target in targets_for_onehot:\n",
    "    temp = pd.get_dummies(finalset[target])\n",
    "    new_df = pd.concat([new_df, temp],axis=1)\n",
    "    \n",
    "new_df = pd.concat([new_df, finalset[['mail_id','ip_id','card_id','bin','amount']]], axis=1)\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "## Get the features and labels\n",
    "x = new_df.values\n",
    "x[x==\"NA\"] = 0\n",
    "x = x.astype(float)\n",
    "y = finalset['bool_fraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(df, idx, key_col):\n",
    "    try:\n",
    "        return df.loc[idx, key_col]\n",
    "    except KeyError:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhiteBoxClassifier():\n",
    "    def __init__(self, columnlists):\n",
    "        self.cvcsupplied_column = columnlists.index(True) # cvcsupplied = True\n",
    "        self.cvcresponsecode0_column = columnlists.index(0) # cvcresponsecode = 0\n",
    "\n",
    "\n",
    "        self.mccredit_column = columnlists.index('mccredit') # mccredit = 1\n",
    "        self.ecommerce_column = columnlists.index('Ecommerce') # Ecommerce = 1\n",
    "\n",
    "        self.MX_column = columnlists.index('MX') # MX = 1\n",
    "         # Ecommerce = 1\n",
    "\n",
    "        self.AU_column = columnlists.index('AU') # AU = 1\n",
    "        # Ecommerce = 1\n",
    "        \n",
    "        print(\"Created a classifier\")\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        pass\n",
    "    \n",
    "    def apply_single_predict(self, x):\n",
    "        if (x[len(x)-1]) or (x[len(x)-2]) or (x[len(x)-3]):\n",
    "            return 1\n",
    "    \n",
    "#         if (x[self.cvcsupplied_column] == 1) and (x[self.cvcresponsecode0_column] == 1):\n",
    "#             return 1\n",
    "        \n",
    "#         if (x[self.mccredit_column] == 1) and (x[self.ecommerce_column] == 1):\n",
    "#             return 1\n",
    "        \n",
    "        if (x[self.MX_column] == 1) and (x[self.ecommerce_column] == 1):\n",
    "            return 1\n",
    "        \n",
    "        if (x[self.AU_column] == 1) and (x[self.ecommerce_column] == 1):\n",
    "            return 1\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        predictions = np.apply_along_axis(self.apply_single_predict, axis=1, arr=x_test)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a classifier\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n"
     ]
    }
   ],
   "source": [
    "## Do the K-fold crossvalidation\n",
    "w_clf = WhiteBoxClassifier(new_df.columns.tolist())\n",
    "\n",
    "total_TP_W = 0\n",
    "total_FP_W = 0\n",
    "total_FN_W = 0\n",
    "total_TN_W = 0\n",
    "\n",
    "total_TP_B = 0\n",
    "total_FP_B = 0\n",
    "total_FN_B = 0\n",
    "total_TN_B = 0\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "iteration = 0\n",
    "for train_indices, test_indices in k_fold.split(x):\n",
    "    iteration = iteration +1\n",
    "    print(\"Iteration \" + str(iteration))\n",
    "    x_train = x[train_indices,:]\n",
    "    y_train = y[train_indices]\n",
    "    x_test = x[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    column_names = new_df.columns.tolist()\n",
    "    additional_train, additional_test = get_grouping_features(x_train, x_test, column_names)\n",
    "    \n",
    "    x_train = np.concatenate((x_train,additional_train),axis=1)\n",
    "    x_test = np.concatenate((x_test,additional_test),axis=1)\n",
    "    \n",
    "    predictions = w_clf.predict(x_test)\n",
    "    TP_W, FP_W, FN_W, TN_W = get_scores(predictions, y_test)\n",
    "    \n",
    "    total_TP_W = total_TP_W + TP_W\n",
    "    total_FP_W = total_FP_W + FP_W\n",
    "    total_FN_W = total_FN_W + FN_W\n",
    "    total_TN_W = total_TN_W + TN_W\n",
    "    \n",
    "    b_clf =  AdaBoostClassifier(n_estimators=100).fit(x_train, y_train)\n",
    "    predictions = b_clf.predict(x_test)\n",
    "    TP_B, FP_B, FN_B, TN_B = get_scores(predictions, y_test)\n",
    "    \n",
    "    total_TP_B = total_TP_B + TP_B\n",
    "    total_FP_B = total_FP_B + FP_B\n",
    "    total_FN_B = total_FN_B + FN_B\n",
    "    total_TN_B = total_TN_B + TN_B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitebox classifier results:\n",
      "TP Whitebox:\t271\n",
      "FP Whitebox:\t31997\n",
      "FN Whitebox:\t74\n",
      "TN Whitebox:\t204694\n",
      "\n",
      "Blackbox classifier results:\n",
      "TP Blackbox:\t0\n",
      "FP Blackbox:\t12\n",
      "FN Blackbox:\t345\n",
      "TN Blackbox:\t236679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Whitebox classifier results:\")\n",
    "print(\"TP Whitebox:\\t\" + str(total_TP_W))\n",
    "print(\"FP Whitebox:\\t\" + str(total_FP_W))\n",
    "print(\"FN Whitebox:\\t\" + str(total_FN_W))\n",
    "print(\"TN Whitebox:\\t\" + str(total_TN_W))\n",
    "print()\n",
    "\n",
    "print(\"Blackbox classifier results:\")\n",
    "print(\"TP Blackbox:\\t\" + str(total_TP_B))\n",
    "print(\"FP Blackbox:\\t\" + str(total_FP_B))\n",
    "print(\"FN Blackbox:\\t\" + str(total_FN_B))\n",
    "print(\"TN Blackbox:\\t\" + str(total_TN_B))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237036"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
