{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some imports might be redundant because the code was split up into pieces\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot size\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_predict, y_true):\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    for i in range(len(y_predict)):\n",
    "        if y_true[i]==1 and y_predict[i]==1:\n",
    "            TP += 1\n",
    "        if y_true[i]==0 and y_predict[i]==1:\n",
    "            FP += 1\n",
    "        if y_true[i]==1 and y_predict[i]==0:\n",
    "            FN += 1\n",
    "        if y_true[i]==0 and y_predict[i]==0:\n",
    "            TN += 1\n",
    "    \n",
    "    return TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Read the data in pandas\n",
    "data = pd.read_csv(\"data_for_student_case.csv\")\n",
    "data['bookingdate'] =  pd.to_datetime(data['bookingdate'])\n",
    "data['creationdate'] =  pd.to_datetime(data['creationdate'])\n",
    "\n",
    "# Delete the refused transactions (but keep them for later use maybe)\n",
    "\n",
    "refused_data = data.loc[data['simple_journal'] == \"Refused\", :]\n",
    "dataset = data.loc[data['simple_journal'] != \"Refused\", :].copy()\n",
    "dataset['bool_fraud'] = (dataset['simple_journal'] == \"Chargeback\").copy().astype(int)\n",
    "dataset['bool_valid'] = (dataset['simple_journal'] == \"Settled\").copy().astype(int)\n",
    "\n",
    "# Do some preprocessing for the ML algorithms\n",
    "finalset = dataset.copy()\n",
    "finalset['mail_id'] = finalset['mail_id'].str.replace('email','')\n",
    "finalset['ip_id'] = finalset['ip_id'].str.replace('ip','')\n",
    "finalset['card_id'] = finalset['card_id'].str.replace('card','')\n",
    "\n",
    "\n",
    "## Transform the data into onehot vectors\n",
    "targets_for_onehot = ['issuercountrycode', 'txvariantcode','currencycode', 'shoppercountrycode', 'shopperinteraction', 'cardverificationcodesupplied', 'cvcresponsecode']\n",
    "\n",
    "new_df = pd.DataFrame([])\n",
    "\n",
    "for target in targets_for_onehot:\n",
    "    temp = pd.get_dummies(finalset[target])\n",
    "    new_df = pd.concat([new_df, temp],axis=1)\n",
    "    \n",
    "new_df = pd.concat([new_df, finalset[['mail_id','ip_id','card_id','bin','amount']]], axis=1)\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "## Get the features and labels\n",
    "x = new_df.values\n",
    "x[x==\"NA\"] = 0\n",
    "x = x.astype(float)\n",
    "y = finalset['bool_fraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/lib/python3/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.16.1)\n"
     ]
    }
   ],
   "source": [
    "## Get the necessary library\n",
    "!pip3 install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "## Create a SMOTE object\n",
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhiteBoxClassifier():\n",
    "    def __init__(self, columnlists):\n",
    "        self.cvcsupplied_column = columnlists.index(True) # cvcsupplied = 1\n",
    "        self.cvcresponsecode0_column = columnlists.index(0) # cvcresponsecode = 1\n",
    "\n",
    "\n",
    "        self.mccredit_column = columnlists.index('mccredit') # mccredit = 1\n",
    "        self.ecommerce_column = columnlists.index('Ecommerce') # Ecommerce = 1\n",
    "\n",
    "        self.MX_column = columnlists.index('MX') # MX = 1\n",
    "         # Ecommerce = 1\n",
    "\n",
    "        self.AU_column = columnlists.index('AU') # AU = 1\n",
    "        # Ecommerce = 1\n",
    "        \n",
    "        print(\"Created a classifier\")\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        pass\n",
    "    \n",
    "    def apply_single_predict(self, x):\n",
    "        if (x[self.cvcsupplied_column] == 1) and (x[self.cvcresponsecode0_column] == 1):\n",
    "            return 1\n",
    "        \n",
    "        if (x[self.mccredit_column] == 1) and (x[self.ecommerce_column] == 1):\n",
    "            return 1\n",
    "        \n",
    "        if (x[self.MX_column] == 1) and (x[self.ecommerce_column] == 1):\n",
    "            return 1\n",
    "        \n",
    "        if (x[self.AU_column] == 1) and (x[self.ecommerce_column] == 1):\n",
    "            return 1\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        predictions = np.apply_along_axis(self.apply_single_predict, axis=1, arr=x_test)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a classifier\n"
     ]
    }
   ],
   "source": [
    "## Do the K-fold crossvalidation\n",
    "w_clf = WhiteBoxClassifier(new_df.columns.tolist())\n",
    "\n",
    "total_TP_W = 0\n",
    "total_FP_W = 0\n",
    "total_FN_W = 0\n",
    "total_TN_W = 0\n",
    "\n",
    "total_TP_B = 0\n",
    "total_FP_B = 0\n",
    "total_FN_B = 0\n",
    "total_TN_B = 0\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "for train_indices, test_indices in k_fold.split(x):\n",
    "    x_train = x[train_indices,:]\n",
    "    y_train = y[train_indices]\n",
    "    x_test = x[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    predictions = w_clf.predict(x_test)\n",
    "    TP_W, FP_W, FN_W, TN_W = get_scores(predictions, y_test)\n",
    "    \n",
    "    total_TP_W = total_TP_W + TP_W\n",
    "    total_FP_W = total_FP_W + FP_W\n",
    "    total_FN_W = total_FN_W + FN_W\n",
    "    total_TN_W = total_TN_W + TN_W\n",
    "    \n",
    "    b_clf = AdaBoostClassifier().fit(x_train, y_train)\n",
    "    predictions = b_clf.predict(x_test)\n",
    "    TP_B, FP_B, FN_B, TN_B = get_scores(predictions, y_test)\n",
    "    \n",
    "    total_TP_B = total_TP_B + TP_B\n",
    "    total_FP_B = total_FP_B + FP_B\n",
    "    total_FN_B = total_FN_B + FN_B\n",
    "    total_TN_B = total_TN_B + TN_B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Whitebox classifier results:\")\n",
    "print(\"TP Whitebox:\\t\" + str(total_TP_W))\n",
    "print(\"FP Whitebox:\\t\" + str(total_FP_W))\n",
    "print(\"FN Whitebox:\\t\" + str(total_FN_W))\n",
    "print(\"TN Whitebox:\\t\" + str(total_TN_W))\n",
    "print()\n",
    "\n",
    "print(\"Blackbox classifier results:\")\n",
    "print(\"TP Blackbox:\\t\" + str(total_TP_B))\n",
    "print(\"FP Blackbox:\\t\" + str(total_FP_B))\n",
    "print(\"FN Blackbox:\\t\" + str(total_FN_B))\n",
    "print(\"TN Blackbox:\\t\" + str(total_TN_B))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
