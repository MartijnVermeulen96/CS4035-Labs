{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some imports might be redundant because the code was split up into pieces\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot size\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(y_predict, y_true):\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    for i in range(len(y_predict)):\n",
    "        if y_true[i]==1 and y_predict[i]==1:\n",
    "            TP += 1\n",
    "        if y_true[i]==0 and y_predict[i]==1:\n",
    "            FP += 1\n",
    "        if y_true[i]==1 and y_predict[i]==0:\n",
    "            FN += 1\n",
    "        if y_true[i]==0 and y_predict[i]==0:\n",
    "            TN += 1\n",
    "    print('TP: '+ str(TP))\n",
    "    print('FP: '+ str(FP))\n",
    "    print('FN: '+ str(FN))\n",
    "    print('TN: '+ str(TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Read the data in pandas\n",
    "data = pd.read_csv(\"data_for_student_case.csv\")\n",
    "data['bookingdate'] =  pd.to_datetime(data['bookingdate'])\n",
    "data['creationdate'] =  pd.to_datetime(data['creationdate'])\n",
    "\n",
    "# Delete the refused transactions (but keep them for later use maybe)\n",
    "\n",
    "refused_data = data.loc[data['simple_journal'] == \"Refused\", :]\n",
    "dataset = data.loc[data['simple_journal'] != \"Refused\", :].copy()\n",
    "dataset['bool_fraud'] = (dataset['simple_journal'] == \"Chargeback\").copy().astype(int)\n",
    "dataset['bool_valid'] = (dataset['simple_journal'] == \"Settled\").copy().astype(int)\n",
    "\n",
    "# Do some preprocessing for the ML algorithms\n",
    "finalset = dataset.copy()\n",
    "finalset['mail_id'] = finalset['mail_id'].str.replace('email','')\n",
    "finalset['ip_id'] = finalset['ip_id'].str.replace('ip','')\n",
    "finalset['card_id'] = finalset['card_id'].str.replace('card','')\n",
    "\n",
    "\n",
    "## Transform the data into onehot vectors\n",
    "targets_for_onehot = ['issuercountrycode', 'txvariantcode','currencycode', 'shoppercountrycode', 'shopperinteraction', 'cardverificationcodesupplied', 'cvcresponsecode']\n",
    "\n",
    "new_df = pd.DataFrame([])\n",
    "\n",
    "for target in targets_for_onehot:\n",
    "    temp = pd.get_dummies(finalset[target])\n",
    "    new_df = pd.concat([new_df, temp],axis=1)\n",
    "    \n",
    "new_df = pd.concat([new_df, finalset[['mail_id','ip_id','card_id','bin','amount']]], axis=1)\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "## Get the features and labels\n",
    "x = new_df.values\n",
    "x[x==\"NA\"] = 0\n",
    "x = x.astype(float)\n",
    "y = finalset['bool_fraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/lib/python3/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.16.1)\n"
     ]
    }
   ],
   "source": [
    "## Get the necessary library\n",
    "!pip3 install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "## Create a SMOTE object\n",
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
