{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data in pandas\n",
    "data = pd.read_csv(\"data_for_student_case.csv\")\n",
    "data['bookingdate'] =  pd.to_datetime(data['bookingdate'])\n",
    "data['creationdate'] =  pd.to_datetime(data['creationdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first entries\n",
    "data.head()\n",
    "# data['simple_journal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the refused transactions (but keep them for later use maybe)\n",
    "\n",
    "refused_data = data.loc[data['simple_journal'] == \"Refused\", :]\n",
    "dataset = data.loc[data['simple_journal'] != \"Refused\", :]\n",
    "dataset['bool_fraud'] = (dataset['simple_journal'] == \"Chargeback\").copy().astype(int)\n",
    "dataset['bool_valid'] = (dataset['simple_journal'] == \"Settled\").copy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some preprocessing for the ML algorithms\n",
    "finalset = dataset.copy()\n",
    "finalset['mail_id'] = finalset['mail_id'].str.replace('email','')\n",
    "finalset['ip_id'] = finalset['ip_id'].str.replace('ip','')\n",
    "finalset['card_id'] = finalset['card_id'].str.replace('card','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group on dates\n",
    "creation_dailygroup_mean = finalset.groupby(pd.Grouper(key='creationdate',freq='D')).mean()\n",
    "creation_monthlygroup_mean = finalset.groupby(pd.Grouper(key='creationdate',freq='M')).mean()\n",
    "booking_dailygroup_mean = finalset.groupby(pd.Grouper(key='bookingdate',freq='D')).mean()\n",
    "booking_monthlygroup_mean = finalset.groupby(pd.Grouper(key='bookingdate',freq='M')).mean()\n",
    "\n",
    "creation_dailygroup_sum = finalset.groupby(pd.Grouper(key='creationdate',freq='D')).sum()\n",
    "creation_monthlygroup_sum = finalset.groupby(pd.Grouper(key='creationdate',freq='M')).sum()\n",
    "booking_dailygroup_sum = finalset.groupby(pd.Grouper(key='bookingdate',freq='D')).sum()\n",
    "booking_monthlygroup_sum = finalset.groupby(pd.Grouper(key='bookingdate',freq='M')).sum()\n",
    "\n",
    "creation_dailygroup_count = finalset.groupby(pd.Grouper(key='creationdate',freq='D')).count()\n",
    "creation_monthlygroup_count = finalset.groupby(pd.Grouper(key='creationdate',freq='M')).count()\n",
    "booking_dailygroup_count = finalset.groupby(pd.Grouper(key='bookingdate',freq='D')).count()\n",
    "booking_monthlygroup_count = finalset.groupby(pd.Grouper(key='bookingdate',freq='M')).count()\n",
    "\n",
    "# Group on simple_journal\n",
    "booking_monthlygroup_count = finalset.groupby(pd.Grouper(key='bookingdate',freq='M')).count()\n",
    "\n",
    "# Group on card id\n",
    "card_id_sum = finalset.groupby('card_id').sum()\n",
    "ip_id_sum = finalset.groupby('ip_id').sum()\n",
    "mail_id_sum = finalset.groupby('mail_id').sum()\n",
    "\n",
    "accountcode_sum = finalset.groupby('accountcode').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=accountcode_sum.index, y=\"bool_fraud\",data=accountcode_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ips = ip_id_sum.sort_values(\"bool_fraud\",ascending=False).head(25)\n",
    "sns.lineplot(data=sorted_ips, x=sorted_ips.index, sort=False, y=\"bool_fraud\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cards = card_id_sum.sort_values(\"bool_fraud\",ascending=False).head(25)\n",
    "sns.lineplot(data=sorted_cards, x=sorted_cards.index, sort=False, y=\"bool_fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_cards = mail_id_sum.sort_values(\"bool_fraud\",ascending=False).head(25)\n",
    "sns.lineplot(data=sorted_cards, x=sorted_cards.index, sort=False, y=\"bool_fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap stuff\n",
    "heatmap_data = pd.pivot_table(finalset, \"simple_journal\", \"shoppercountrycode\",\"shopperinteraction\", aggfunc=lambda x: sum(x == \"Chargeback\"))\n",
    "ax = sns.heatmap(heatmap_data.fillna(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap stuff\n",
    "heatmap_data = pd.pivot_table(finalset, \"simple_journal\", \"txvariantcode\",\"shopperinteraction\", aggfunc=lambda x: sum(x == \"Chargeback\"))\n",
    "ax = sns.heatmap(heatmap_data.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap stuff\n",
    "heatmap_data = pd.pivot_table(finalset, \"simple_journal\", \"card_id\",\"shopperinteraction\", aggfunc=lambda x: sum(x == \"Chargeback\"))\n",
    "ax = sns.heatmap(heatmap_data.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Heatmap stuff\n",
    "# heatmap_data = pd.pivot_table(finalset, \"simple_journal\", \"ip_id\",\"shopperinteraction\", aggfunc=lambda x: sum(x == \"Chargeback\"))\n",
    "# ax = sns.heatmap(heatmap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Heatmap stuff\n",
    "# heatmap_data = pd.pivot_table(finalset, \"simple_journal\", \"accountcode\",\"shopperinteraction\", aggfunc=lambda x: sum(x == \"Chargeback\"))\n",
    "# ax = sns.heatmap(heatmap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple line plot\n",
    "ax = sns.lineplot(x=creation_dailygroup_sum.index, y=\"bool_fraud\", data=creation_dailygroup_sum)\n",
    "ax.set_xticklabels(labels = [d.date() for d in creation_dailygroup_sum.index], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple line plot\n",
    "ax = sns.barplot(x=creation_monthlygroup_sum.index, y=\"bool_fraud\", data=creation_monthlygroup_sum)\n",
    "ax.set_xticklabels(labels = [d.date() for d in creation_monthlygroup_sum.index], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_monthlygroup_sum.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issuercountry\n",
    "# txvariantcode\n",
    "# currencycode\n",
    "# shoppercountry\n",
    "# interaction\n",
    "# verification\n",
    "# accountcode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_onehot = ['issuercountrycode', 'txvariantcode','currencycode', 'shoppercountrycode', 'shopperinteraction', 'cardverificationcodesupplied', 'cvcresponsecode']\n",
    "\n",
    "new_df = pd.DataFrame([])\n",
    "\n",
    "for target in targets_for_onehot:\n",
    "    temp = pd.get_dummies(finalset[target])\n",
    "    new_df = pd.concat([new_df, temp],axis=1)\n",
    "    \n",
    "new_df = pd.concat([new_df, finalset['creationdate'].apply(lambda x: x.timestamp())], axis=1)\n",
    "new_df = pd.concat([new_df, finalset[['mail_id','ip_id','card_id','bin','amount']]], axis=1)\n",
    "new_df = new_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(y_predict, y_true):\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    for i in range(len(y_predict)):\n",
    "        if y_true[i]==1 and y_predict[i]==1:\n",
    "            TP += 1\n",
    "        if y_true[i]==0 and y_predict[i]==1:\n",
    "            FP += 1\n",
    "        if y_true[i]==1 and y_predict[i]==0:\n",
    "            FN += 1\n",
    "        if y_true[i]==0 and y_predict[i]==0:\n",
    "            TN += 1\n",
    "    print('TP: '+ str(TP))\n",
    "    print('FP: '+ str(FP))\n",
    "    print('FN: '+ str(FN))\n",
    "    print('TN: '+ str(TN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = new_df.values\n",
    "x[x==\"NA\"] = 0\n",
    "y = finalset['bool_fraud'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1)#test_size: proportion of train/test data\n",
    "clf = neighbors.KNeighborsClassifier(algorithm = 'kd_tree')\n",
    "clf.fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "#print confusion_matrix(y_test, answear) watch out the element in confusion matrix\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_predict)\n",
    "predict_proba = clf.predict_proba(x_test)#the probability of each smple labelled to positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "## Run the svm\n",
    "\n",
    "# clf = svm.SVC(kernel='linear', C=1).fit(x_train, y_train)\n",
    "# clf.score(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "## Run the decision tree\n",
    "clf = tree.DecisionTreeClassifier(class_weight={0:1, 1:10000}).fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test) \n",
    "print_scores(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "## Run the AdaBoost class\n",
    "clf = AdaBoostClassifier(n_estimators=100, base_estimator=tree.DecisionTreeClassifier(class_weight={0:1, 1:100}, max_depth=1)).fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test) \n",
    "print_scores(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Run the bagging\n",
    "clf = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5).fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test) \n",
    "print_scores(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Run the Forsest\n",
    "clf = RandomForestClassifier(n_estimators=100).fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test) \n",
    "print_scores(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test) - sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
